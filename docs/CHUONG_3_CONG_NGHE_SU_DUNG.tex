\documentclass[../DoAn.tex]{subfiles}
\begin{document}

\section*{M·ªü ƒë·∫ßu ch∆∞∆°ng}

Ch∆∞∆°ng n√†y tr√¨nh b√†y c√°c c√¥ng ngh·ªá v√† n·ªÅn t·∫£ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong qu√° tr√¨nh ph√°t tri·ªÉn h·ªá th·ªëng AI NVCB. M·ªói c√¥ng ngh·ªá ƒë∆∞·ª£c l·ª±a ch·ªçn ƒë·ªÅu nh·∫±m gi·∫£i quy·∫øt c√°c y√™u c·∫ßu c·ª• th·ªÉ ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh t·∫°i Ch∆∞∆°ng 2, bao g·ªìm: (i) x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM), (ii) x√¢y d·ª±ng backend API hi·ªáu nƒÉng cao, (iii) ph√°t tri·ªÉn giao di·ªán ng∆∞·ªùi d√πng th√¢n thi·ªán, (iv) l∆∞u tr·ªØ v√† truy v·∫•n vector cho RAG, v√† (v) t·∫°o file PowerPoint t·ª± ƒë·ªông. V·ªõi m·ªói c√¥ng ngh·ªá, sinh vi√™n s·∫Ω ph√¢n t√≠ch c√°c l·ª±a ch·ªçn thay th·∫ø v√† gi·∫£i th√≠ch l√Ω do l·ª±a ch·ªçn.

\noindent\rule{\linewidth}{0.4pt}

\section{Ki·∫øn tr√∫c t·ªïng quan h·ªá th·ªëng}

H·ªá th·ªëng AI NVCB ƒë∆∞·ª£c x√¢y d·ª±ng theo ki·∫øn tr√∫c ph√¢n l·ªõp (Layered Architecture) k·∫øt h·ª£p v·ªõi ki·∫øn tr√∫c microservices, bao g·ªìm ba t·∫ßng ch√≠nh: t·∫ßng tr√¨nh b√†y (Presentation Layer), t·∫ßng nghi·ªáp v·ª• (Business Logic Layer), v√† t·∫ßng d·ªØ li·ªáu (Data Layer). Ki·∫øn tr√∫c n√†y ƒë√°p ·ª©ng y√™u c·∫ßu phi ch·ª©c nƒÉng NFR18 v·ªÅ t√≠nh d·ªÖ b·∫£o tr√¨ ƒë√£ n√™u t·∫°i m·ª•c 2.4.5.

\setcounter{figure}{7}
\begin{figure}[H]
    \centering
    \includegraphics{Hinhve/Picture8.png}
    \caption{V√≠ d·ª• bi·ªÉu ƒë·ªì ph·ª• thu·ªôc g√≥i}
    \label{fig:Fig8}
\end{figure}

Ki·∫øn tr√∫c n√†y mang l·∫°i nhi·ªÅu l·ª£i √≠ch: (i) t√°ch bi·ªát r√µ r√†ng c√°c th√†nh ph·∫ßn gi√∫p d·ªÖ d√†ng b·∫£o tr√¨ v√† m·ªü r·ªông, (ii) cho ph√©p thay ƒë·ªïi c√¥ng ngh·ªá ·ªü m·ªôt t·∫ßng m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c t·∫ßng kh√°c, v√† (iii) h·ªó tr·ª£ tri·ªÉn khai ƒë·ªôc l·∫≠p c√°c th√†nh ph·∫ßn th√¥ng qua Docker container.

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† LLM}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

Theo y√™u c·∫ßu t·∫°i Ch∆∞∆°ng 2, h·ªá th·ªëng c·∫ßn th·ª±c hi·ªán c√°c t√°c v·ª• x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n ph·ª©c t·∫°p bao g·ªìm: (i) t√≥m t·∫Øt t√†i li·ªáu t·ª± ƒë·ªông (UC01.2), (ii) h·ªèi ƒë√°p d·ª±a tr√™n ng·ªØ c·∫£nh t√†i li·ªáu - RAG (UC01.3), (iii) sinh n·ªôi dung slide t·ª´ ch·ªß ƒë·ªÅ ho·∫∑c t√†i li·ªáu (UC02), v√† (iv) t·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám t·ª± ƒë·ªông (UC03). ƒê√¢y l√† c√°c t√°c v·ª• ƒë√≤i h·ªèi kh·∫£ nƒÉng hi·ªÉu v√† sinh ng√¥n ng·ªØ t·ª± nhi√™n ·ªü m·ª©c ƒë·ªô cao.

\subsection{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá}

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{3.2cm}|p{3.2cm}|p{4.6cm}|p{4.6cm}|}
        \hline
        \textbf{C√¥ng ngh·ªá} & \textbf{M√¥ t·∫£} & \textbf{∆Øu ƒëi·ªÉm} & \textbf{Nh∆∞·ª£c ƒëi·ªÉm} \\ \hline
        \textbf{OpenAI GPT API} & API t·ª´ OpenAI & Ch·∫•t l∆∞·ª£ng cao, d·ªÖ t√≠ch h·ª£p & Chi ph√≠ cao, ph·ª• thu·ªôc internet, d·ªØ li·ªáu g·ª≠i l√™n cloud \\ \hline
        \textbf{Google Gemini API} & API t·ª´ Google & ƒêa ph∆∞∆°ng th·ª©c, t√≠ch h·ª£p Google & Ph·ª• thu·ªôc cloud, chi ph√≠ theo usage \\ \hline
        \textbf{Hugging Face Transformers} & Th∆∞ vi·ªán m√£ ngu·ªìn m·ªü & Mi·ªÖn ph√≠, nhi·ªÅu model & Y√™u c·∫ßu GPU m·∫°nh, c·∫•u h√¨nh ph·ª©c t·∫°p \\ \hline
        \textbf{Ollama + LangChain} & LLM server local + Framework orchestration & Mi·ªÖn ph√≠, ch·∫°y offline, b·∫£o m·∫≠t cao & Y√™u c·∫ßu ph·∫ßn c·ª©ng, hi·ªáu nƒÉng ph·ª• thu·ªôc model \\ \hline
    \end{tabular}
    \caption{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† LLM}
    \label{tab:llm_tech_choices}
\end{table}

\subsection{L·ª±a ch·ªçn: Ollama k·∫øt h·ª£p LangChain}

H·ªá th·ªëng AI NVCB l·ª±a ch·ªçn s·ª≠ d·ª•ng \textbf{Ollama} l√†m LLM server v√† \textbf{LangChain} l√†m framework ƒëi·ªÅu ph·ªëi (orchestration) v√¨ c√°c l√Ω do sau:

	extbf{Ollama} \cite{ollama_docs} l√† m·ªôt n·ªÅn t·∫£ng m√£ ngu·ªìn m·ªü cho ph√©p ch·∫°y c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM) tr·ª±c ti·∫øp tr√™n m√°y t√≠nh c√° nh√¢n. Ollama ƒë√≥ng g√≥i model weights, c·∫•u h√¨nh v√† d·ªØ li·ªáu v√†o m·ªôt ƒë∆°n v·ªã duy nh·∫•t ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong Modelfile, gi√∫p vi·ªác c√†i ƒë·∫∑t v√† ch·∫°y model tr·ªü n√™n ƒë∆°n gi·∫£n. M·ªôt s·ªë ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t c·ªßa Ollama bao g·ªìm:

Th·ª© nh·∫•t, Ollama h·ªó tr·ª£ tri·ªÉn khai on-premise, ƒë√°p ·ª©ng y√™u c·∫ßu NFR14 v·ªÅ b·∫£o m·∫≠t d·ªØ li·ªáu. To√†n b·ªô qu√° tr√¨nh x·ª≠ l√Ω di·ªÖn ra tr√™n m√°y ch·ªß n·ªôi b·ªô, kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c g·ª≠i ra ngo√†i. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát quan tr·ªçng khi ng∆∞·ªùi d√πng l√†m vi·ªác v·ªõi t√†i li·ªáu nh·∫°y c·∫£m.

Th·ª© hai, Ollama cung c·∫•p API t∆∞∆°ng th√≠ch v·ªõi chu·∫©n OpenAI, cho ph√©p d·ªÖ d√†ng t√≠ch h·ª£p v·ªõi c√°c framework nh∆∞ LangChain. API endpoint m·∫∑c ƒë·ªãnh t·∫°i \texttt{http://localhost:11434} cung c·∫•p c√°c endpoint \texttt{/api/generate}, \texttt{/api/chat}, v√† \texttt{/api/embeddings}.

Th·ª© ba, Ollama h·ªó tr·ª£ nhi·ªÅu model LLM ph·ªï bi·∫øn nh∆∞ Llama 2, Llama 3, Mistral, Gemma, Phi-3, v√† Qwen2.5. Ng∆∞·ªùi d√πng c√≥ th·ªÉ linh ho·∫°t ch·ªçn model ph√π h·ª£p v·ªõi y√™u c·∫ßu v·ªÅ ch·∫•t l∆∞·ª£ng v√† t√†i nguy√™n ph·∫ßn c·ª©ng, ƒë√°p ·ª©ng y√™u c·∫ßu UC04 v·ªÅ qu·∫£n l√Ω model AI.

	extbf{LangChain} \cite{langchain_docs} l√† m·ªôt framework m√£ ngu·ªìn m·ªü ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng LLM. Framework n√†y cung c·∫•p c√°c abstraction v√† component gi√∫p ƒë∆°n gi·∫£n h√≥a vi·ªác ph√°t tri·ªÉn ·ª©ng d·ª•ng AI ph·ª©c t·∫°p:

V·ªÅ m·∫∑t ki·∫øn tr√∫c, LangChain ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh c√°c module ch√≠nh: (i) Models - giao ti·∫øp v·ªõi c√°c LLM, (ii) Prompts - qu·∫£n l√Ω v√† t·ªëi ∆∞u prompt templates, (iii) Chains - k·∫øt n·ªëi nhi·ªÅu component th√†nh pipeline x·ª≠ l√Ω, (iv) Memory - l∆∞u tr·ªØ ng·ªØ c·∫£nh h·ªôi tho·∫°i, v√† (v) Retrieval - t√≠ch h·ª£p v·ªõi vector stores cho RAG.

ƒê·ªëi v·ªõi t√≠nh nƒÉng RAG (Retrieval-Augmented Generation) ph·ª•c v·ª• use case UC01.3, LangChain cung c·∫•p pipeline ho√†n ch·ªânh bao g·ªìm: document loaders ƒë·ªÉ ƒë·ªçc nhi·ªÅu ƒë·ªãnh d·∫°ng file, text splitters ƒë·ªÉ chia nh·ªè vƒÉn b·∫£n, embeddings ƒë·ªÉ chuy·ªÉn ƒë·ªïi text th√†nh vector, v√† retrievers ƒë·ªÉ t√¨m ki·∫øm ng·ªØ c·∫£nh li√™n quan.

\begin{verbatim}
# V√≠ d·ª• s·ª≠ d·ª•ng LangChain v·ªõi Ollama trong h·ªá th·ªëng
from langchain_community.llms import Ollama
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

llm = Ollama(model="qwen3:8b", base_url="http://localhost:11434")
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="D·ª±a tr√™n ng·ªØ c·∫£nh: {context}\nTr·∫£ l·ªùi c√¢u h·ªèi: {question}"
)
chain = LLMChain(llm=llm, prompt=prompt)
\end{verbatim}

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá Backend API}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

H·ªá th·ªëng c·∫ßn m·ªôt backend API c√≥ kh·∫£ nƒÉng: (i) x·ª≠ l√Ω c√°c request HTTP t·ª´ frontend m·ªôt c√°ch hi·ªáu qu·∫£, (ii) h·ªó tr·ª£ upload file ƒëa ƒë·ªãnh d·∫°ng, (iii) x·ª≠ l√Ω b·∫•t ƒë·ªìng b·ªô (async) cho c√°c t√°c v·ª• AI t·ªën th·ªùi gian, v√† (iv) cung c·∫•p t√†i li·ªáu API t·ª± ƒë·ªông. C√°c y√™u c·∫ßu n√†y li√™n quan ƒë·∫øn NFR01-03 v·ªÅ hi·ªáu nƒÉng v√† NFR06-07 v·ªÅ ƒë·ªô tin c·∫≠y.

\subsection{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá}

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{3.2cm}|p{2.2cm}|p{5.0cm}|p{5.2cm}|}
        \hline
        \textbf{Framework} & \textbf{Ng√¥n ng·ªØ} & \textbf{∆Øu ƒëi·ªÉm} & \textbf{Nh∆∞·ª£c ƒëi·ªÉm} \\ \hline
        \textbf{Django} & Python & Full-featured, ORM m·∫°nh, c·ªông ƒë·ªìng l·ªõn & N·∫∑ng, learning curve cao, kh√¥ng t·ªëi ∆∞u cho API \\ \hline
        \textbf{Flask} & Python & Nh·∫π, linh ho·∫°t, d·ªÖ h·ªçc & Kh√¥ng c√≥ async native, thi·∫øu validation t·ª± ƒë·ªông \\ \hline
        \textbf{Express.js} & Node.js & Nhanh, ecosystem l·ªõn & Kh√¥ng ph√π h·ª£p v·ªõi AI/ML Python ecosystem \\ \hline
        \textbf{FastAPI} & Python & Async native, t·ª± ƒë·ªông gen docs, validation m·∫°nh & C√≤n m·ªõi, c·ªông ƒë·ªìng nh·ªè h∆°n Django \\ \hline
    \end{tabular}
    \caption{C√°c l·ª±a ch·ªçn framework backend API}
    \label{tab:backend_framework_choices}
\end{table}

\subsection{L·ª±a ch·ªçn: FastAPI}

	extbf{FastAPI} \cite{fastapi_docs} ƒë∆∞·ª£c l·ª±a ch·ªçn l√†m framework backend ch√≠nh v√¨ c√°c ∆∞u ƒëi·ªÉm sau:

FastAPI l√† m·ªôt web framework hi·ªán ƒë·∫°i, hi·ªáu nƒÉng cao cho Python, ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n n·ªÅn t·∫£ng Starlette (cho web) v√† Pydantic (cho data validation). Theo benchmark ch√≠nh th·ª©c, FastAPI l√† m·ªôt trong nh·ªØng framework Python nhanh nh·∫•t, t∆∞∆°ng ƒë∆∞∆°ng v·ªõi NodeJS v√† Go.

V·ªÅ h·ªó tr·ª£ async/await, FastAPI ƒë∆∞·ª£c thi·∫øt k·∫ø v·ªõi async-first approach, cho ph√©p x·ª≠ l√Ω nhi·ªÅu request ƒë·ªìng th·ªùi m√† kh√¥ng block thread. ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát quan tr·ªçng khi t√≠ch h·ª£p v·ªõi LLM v√¨ c√°c t√°c v·ª• AI th∆∞·ªùng c√≥ latency cao (10-60 gi√¢y theo NFR01-03).

\begin{verbatim}
# V√≠ d·ª• endpoint async trong FastAPI
@router.post("/analyze")
async def analyze_document(
    file: UploadFile = File(...),
    query_type: str = Form(...),
    model_name: Optional[str] = Form(None)
) -> Dict[str, Any]:
    content = await file.read()
    result = await document_service.analyze(content, query_type)
    return {"status": "success", "result": result}
\end{verbatim}

V·ªÅ t√≠nh nƒÉng t·ª± ƒë·ªông sinh t√†i li·ªáu API, FastAPI t·ª± ƒë·ªông t·∫°o OpenAPI (Swagger) documentation t·ª´ type hints v√† Pydantic models. Giao di·ªán Swagger UI t·∫°i \texttt{/docs} cho ph√©p developers v√† testers d·ªÖ d√†ng ki·ªÉm th·ª≠ API m√† kh√¥ng c·∫ßn c√¥ng c·ª• b√™n ngo√†i.

V·ªÅ data validation, FastAPI s·ª≠ d·ª•ng Pydantic ƒë·ªÉ validate d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª± ƒë·ªông d·ª±a tr√™n type annotations. Khi d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá, h·ªá th·ªëng tr·∫£ v·ªÅ response l·ªói chi ti·∫øt v·ªõi HTTP status code 422, gi√∫p frontend d·ªÖ d√†ng x·ª≠ l√Ω v√† hi·ªÉn th·ªã th√¥ng b√°o cho ng∆∞·ªùi d√πng.

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá Frontend}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

Giao di·ªán ng∆∞·ªùi d√πng c·∫ßn ƒë√°p ·ª©ng c√°c y√™u c·∫ßu: (i) th√¢n thi·ªán v√† d·ªÖ s·ª≠ d·ª•ng (NFR10), (ii) h·ªó tr·ª£ ti·∫øng Vi·ªát ho√†n to√†n (NFR11), (iii) hi·ªÉn th·ªã tr·∫°ng th√°i x·ª≠ l√Ω realtime (NFR12), v√† (iv) c√≥ th·ªÉ ph√°t tri·ªÉn nhanh ƒë·ªÉ t·∫≠p trung v√†o logic nghi·ªáp v·ª•.

\subsection{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá}

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{3.2cm}|p{2.4cm}|p{5.0cm}|p{5.0cm}|}
        \hline
        \textbf{C√¥ng ngh·ªá} & \textbf{Lo·∫°i} & \textbf{∆Øu ƒëi·ªÉm} & \textbf{Nh∆∞·ª£c ƒëi·ªÉm} \\ \hline
        \textbf{React} & SPA Framework & Linh ho·∫°t, ecosystem l·ªõn, hi·ªáu nƒÉng t·ªët & Learning curve cao, c·∫ßn build pipeline ph·ª©c t·∫°p \\ \hline
        \textbf{Vue.js} & SPA Framework & D·ªÖ h·ªçc, documentation t·ªët & C·ªông ƒë·ªìng nh·ªè h∆°n React \\ \hline
        \textbf{Gradio} & Python UI & D√†nh cho ML/AI, d·ªÖ d√πng & Gi·ªõi h·∫°n t√πy ch·ªânh giao di·ªán \\ \hline
        \textbf{Streamlit} & Python UI & Rapid prototyping, code Python thu·∫ßn, t√≠ch h·ª£p data science & Hi·ªáu nƒÉng th·∫•p h∆°n SPA, gi·ªõi h·∫°n layout \\ \hline
    \end{tabular}
    \caption{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá frontend}
    \label{tab:frontend_tech_choices}
\end{table}

\subsection{L·ª±a ch·ªçn: Streamlit}

	extbf{Streamlit} \cite{streamlit_docs} ƒë∆∞·ª£c l·ª±a ch·ªçn l√†m framework frontend v√¨ c√°c l√Ω do sau:

Streamlit l√† m·ªôt framework m√£ ngu·ªìn m·ªü cho ph√©p x√¢y d·ª±ng ·ª©ng d·ª•ng web data science v√† machine learning ch·ªâ v·ªõi Python. ƒêi·ªÉm m·∫°nh c·ªßa Streamlit n·∫±m ·ªü kh·∫£ nƒÉng rapid development - t·ª´ √Ω t∆∞·ªüng ƒë·∫øn prototype ch·ªâ trong v√†i gi·ªù thay v√¨ v√†i ng√†y.

V·ªÅ m√¥ h√¨nh l·∫≠p tr√¨nh, Streamlit s·ª≠ d·ª•ng declarative paradigm - developers khai b√°o UI elements v√† Streamlit t·ª± ƒë·ªông handle re-rendering khi state thay ƒë·ªïi. Script Python ƒë∆∞·ª£c ch·∫°y t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi m·ªói khi c√≥ interaction, v·ªõi c∆° ch·∫ø caching th√¥ng minh ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng.

\begin{verbatim}
# V√≠ d·ª• code Streamlit trong h·ªá th·ªëng
import streamlit as st

st.set_page_config(page_title="Ph√¢n T√≠ch T√†i Li·ªáu AI", page_icon="üìÑ")
st.title("üìÑ Ph√¢n T√≠ch T√†i Li·ªáu AI")

uploaded_file = st.file_uploader("T·∫£i t√†i li·ªáu", type=["pdf", "docx", "txt"])
if uploaded_file:
    with st.spinner("ƒêang ph√¢n t√≠ch..."):
        result = analyze_document(uploaded_file)
    st.success("Ph√¢n t√≠ch ho√†n t·∫•t!")
    st.write(result)
\end{verbatim}

V·ªÅ t√≠ch h·ª£p v·ªõi Python ecosystem, Streamlit t√≠ch h·ª£p seamless v·ªõi c√°c th∆∞ vi·ªán Python ph·ªï bi·∫øn nh∆∞ Pandas, NumPy, Matplotlib, v√† ƒë·∫∑c bi·ªát l√† c√°c th∆∞ vi·ªán AI/ML. ƒêi·ªÅu n√†y cho ph√©p t·∫≠n d·ª•ng to√†n b·ªô code Python ƒë√£ vi·∫øt cho backend.

V·ªÅ h·ªó tr·ª£ realtime updates, Streamlit cung c·∫•p c√°c widget nh∆∞ \texttt{st.spinner()}, \texttt{st.progress()}, v√† \texttt{st.status()} ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i x·ª≠ l√Ω, ƒë√°p ·ª©ng y√™u c·∫ßu NFR12. Session state cho ph√©p l∆∞u tr·ªØ d·ªØ li·ªáu gi·ªØa c√°c l·∫ßn rerun, h·ªó tr·ª£ t√≠nh nƒÉng l·ªãch s·ª≠ h·ªôi tho·∫°i (UC01.4).

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá Vector Database v√† Embeddings}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

T√≠nh nƒÉng RAG (Retrieval-Augmented Generation) trong use case UC01.3 y√™u c·∫ßu: (i) chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector (embeddings), (ii) l∆∞u tr·ªØ v√† index vector hi·ªáu qu·∫£, v√† (iii) t√¨m ki·∫øm semantic similarity nhanh ch√≥ng. ƒê√¢y l√† th√†nh ph·∫ßn c·ªët l√µi ƒë·ªÉ LLM c√≥ th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu c·ª• th·ªÉ thay v√¨ ki·∫øn th·ª©c t·ªïng qu√°t.

\subsection{K·ªπ thu·∫≠t RAG (Retrieval-Augmented Generation)}

RAG \cite{lewis2020rag} l√† m·ªôt k·ªπ thu·∫≠t k·∫øt h·ª£p kh·∫£ nƒÉng truy xu·∫•t th√¥ng tin (retrieval) v·ªõi kh·∫£ nƒÉng sinh vƒÉn b·∫£n (generation) c·ªßa LLM. Thay v√¨ ch·ªâ d·ª±a v√†o ki·∫øn th·ª©c ƒë∆∞·ª£c hu·∫•n luy·ªán s·∫µn, LLM ƒë∆∞·ª£c cung c·∫•p th√™m ng·ªØ c·∫£nh (context) t·ª´ ngu·ªìn d·ªØ li·ªáu b√™n ngo√†i ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi ch√≠nh x√°c v√† c·∫≠p nh·∫≠t h∆°n.

Quy tr√¨nh RAG bao g·ªìm c√°c b∆∞·ªõc: (i) Indexing - chia t√†i li·ªáu th√†nh chunks v√† chuy·ªÉn th√†nh embeddings, (ii) Retrieval - khi c√≥ c√¢u h·ªèi, t√¨m c√°c chunks li√™n quan nh·∫•t d·ª±a tr√™n similarity, v√† (iii) Generation - k·∫øt h·ª£p c√¢u h·ªèi v·ªõi context ƒë·ªÉ t·∫°o prompt cho LLM.

\begin{verbatim}
@startuml
skinparam activityShape octagon
skinparam backgroundColor white

title QUY TR√åNH RAG TRONG H·ªÜ TH·ªêNG

partition "GIAI ƒêO·∫†N INDEXING" #LightBlue {
    :T√†i li·ªáu (PDF/DOCX);    
    :Text Splitter;
    note right: Chia vƒÉn b·∫£n th√†nh chunks
    :Embedding Model;
    note right: Chuy·ªÉn text ‚Üí vector
    :FAISS Vector Store;
    note right: L∆∞u tr·ªØ v√† index vectors
}

partition "GIAI ƒêO·∫†N RETRIEVAL + GENERATION" #LightGreen {
    :C√¢u h·ªèi ng∆∞·ªùi d√πng;
    :Embedding Model;
    note right: Chuy·ªÉn c√¢u h·ªèi ‚Üí vector
    :Similarity Search;
    note right: T√¨m vectors t∆∞∆°ng t·ª±
    :Top-K Chunks;
    note right: L·∫•y K chunks li√™n quan nh·∫•t
    :Prompt (Q + Context);
    note right: K·∫øt h·ª£p c√¢u h·ªèi + context
    :LLM (Ollama);
    note right: Sinh c√¢u tr·∫£ l·ªùi
    :C√¢u tr·∫£ l·ªùi;
}

@enduml
\end{verbatim}

\subsection{C√°c l·ª±a ch·ªçn Vector Database}

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{3.2cm}|p{2.6cm}|p{5.0cm}|p{5.0cm}|}
        \hline
        \textbf{C√¥ng ngh·ªá} & \textbf{Lo·∫°i} & \textbf{∆Øu ƒëi·ªÉm} & \textbf{Nh∆∞·ª£c ƒëi·ªÉm} \\ \hline
        \textbf{Pinecone} & Cloud managed & Scalable, d·ªÖ d√πng & Chi ph√≠ cao, ph·ª• thu·ªôc cloud \\ \hline
        \textbf{Weaviate} & Self-hosted & GraphQL API, multi-modal & C·∫•u h√¨nh ph·ª©c t·∫°p \\ \hline
        \textbf{Chroma} & Embedded & Nh·∫π, d·ªÖ t√≠ch h·ª£p & Ch∆∞a mature, gi·ªõi h·∫°n scale \\ \hline
        \textbf{FAISS} & Library & Nhanh, mi·ªÖn ph√≠, ch·∫°y local & Kh√¥ng c√≥ API server, c·∫ßn code \\ \hline
    \end{tabular}
    \caption{C√°c l·ª±a ch·ªçn Vector Database}
    \label{tab:vector_db_choices}
\end{table}

\subsection{L·ª±a ch·ªçn: FAISS v·ªõi HuggingFace Embeddings}

	extbf{FAISS} (Facebook AI Similarity Search) \cite{johnson2019faiss} l√† th∆∞ vi·ªán m√£ ngu·ªìn m·ªü c·ªßa Meta AI, ƒë∆∞·ª£c thi·∫øt k·∫ø cho vi·ªác t√¨m ki·∫øm similarity hi·ªáu qu·∫£ tr√™n t·∫≠p d·ªØ li·ªáu vector l·ªõn. FAISS ƒë∆∞·ª£c l·ª±a ch·ªçn v√¨:

Th·ª© nh·∫•t, FAISS ho·∫°t ƒë·ªông ho√†n to√†n offline, ph√π h·ª£p v·ªõi y√™u c·∫ßu tri·ªÉn khai on-premise (NFR14). Kh√¥ng c√≥ d·ªØ li·ªáu vector n√†o ƒë∆∞·ª£c g·ª≠i ra ngo√†i h·ªá th·ªëng.

Th·ª© hai, FAISS cung c·∫•p nhi·ªÅu index types (Flat, IVF, HNSW) cho ph√©p c√¢n b·∫±ng gi·ªØa accuracy v√† speed. V·ªõi quy m√¥ d·ªØ li·ªáu c·ªßa h·ªá th·ªëng (t√†i li·ªáu t·ª´ng ng∆∞·ªùi d√πng), IndexFlatL2 ƒë∆°n gi·∫£n l√† ƒë·ªß hi·ªáu qu·∫£.

Th·ª© ba, FAISS t√≠ch h·ª£p s·∫µn v·ªõi LangChain th√¥ng qua \texttt{langchain_community.vectorstores.FAISS}, gi√∫p vi·ªác implementation ƒë∆°n gi·∫£n v√† nh·∫•t qu√°n v·ªõi architecture.

	extbf{Sentence Transformers} \cite{reimers2019sentencebert} v·ªõi model \texttt{all-MiniLM-L6-v2} ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o embeddings. Model n√†y c√¢n b·∫±ng t·ªët gi·ªØa ch·∫•t l∆∞·ª£ng embedding v√† t·ªëc ƒë·ªô x·ª≠ l√Ω, v·ªõi k√≠ch th∆∞·ªõc vector 384 chi·ªÅu v√† c√≥ th·ªÉ ch·∫°y tr√™n CPU.

\begin{verbatim}
# V√≠ d·ª• s·ª≠ d·ª•ng FAISS v·ªõi LangChain
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = text_splitter.split_documents(documents)
vector_store = FAISS.from_documents(chunks, embeddings)
\end{verbatim}

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá t·∫°o file PowerPoint}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

Use case UC02 y√™u c·∫ßu h·ªá th·ªëng t·ª± ƒë·ªông t·∫°o file PowerPoint (.pptx) t·ª´ n·ªôi dung ƒë∆∞·ª£c sinh b·ªüi LLM. File output c·∫ßn ƒë√°p ·ª©ng: (i) ƒë·ªãnh d·∫°ng chu·∫©n Microsoft PowerPoint, (ii) h·ªó tr·ª£ Unicode ti·∫øng Vi·ªát, v√† (iii) c√≥ th·ªÉ m·ªü v√† ch·ªânh s·ª≠a b·∫±ng c√°c ph·∫ßn m·ªÅm tr√¨nh chi·∫øu ph·ªï bi·∫øn.

\subsection{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá}

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{3.2cm}|p{2.2cm}|p{5.0cm}|p{5.4cm}|}
        \hline
        \textbf{C√¥ng ngh·ªá} & \textbf{Ng√¥n ng·ªØ} & \textbf{∆Øu ƒëi·ªÉm} & \textbf{Nh∆∞·ª£c ƒëi·ªÉm} \\ \hline
        \textbf{Apache POI} & Java & Full-featured, mature & C·∫ßn JVM, kh√¥ng ph√π h·ª£p Python stack \\ \hline
        \textbf{python-pptx} & Python & Native Python, API ƒë∆°n gi·∫£n & M·ªôt s·ªë t√≠nh nƒÉng n√¢ng cao thi·∫øu \\ \hline
        \textbf{Aspose.Slides} & Multi & Enterprise-grade & Chi ph√≠ license cao \\ \hline
        \textbf{Google Slides API} & Cloud & T√≠ch h·ª£p Google & C·∫ßn internet, ph·ª• thu·ªôc cloud \\ \hline
    \end{tabular}
    \caption{C√°c l·ª±a ch·ªçn c√¥ng ngh·ªá t·∫°o file PowerPoint}
    \label{tab:pptx_tech_choices}
\end{table}

\subsection{L·ª±a ch·ªçn: python-pptx}

	extbf{python-pptx} \cite{python_pptx_docs} l√† th∆∞ vi·ªán Python cho ph√©p t·∫°o v√† c·∫≠p nh·∫≠t file PowerPoint (.pptx). Th∆∞ vi·ªán n√†y ƒë∆∞·ª£c l·ª±a ch·ªçn v√¨:

V·ªÅ t√≠nh t∆∞∆°ng th√≠ch, python-pptx t·∫°o file .pptx chu·∫©n Office Open XML (OOXML) c√≥ th·ªÉ m·ªü b·∫±ng Microsoft PowerPoint, LibreOffice Impress, v√† Google Slides. ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o file output c√≥ th·ªÉ s·ª≠ d·ª•ng tr√™n nhi·ªÅu n·ªÅn t·∫£ng.

V·ªÅ API design, python-pptx cung c·∫•p object model tr·ª±c quan: Presentation ‚Üí Slides ‚Üí Shapes ‚Üí Text Frames ‚Üí Paragraphs ‚Üí Runs. Developers c√≥ th·ªÉ d·ªÖ d√†ng t·∫°o slide, th√™m title, content, v√† ƒë·ªãnh d·∫°ng text.

\begin{verbatim}
# V√≠ d·ª• t·∫°o slide v·ªõi python-pptx
from pptx import Presentation
from pptx.util import Inches, Pt

prs = Presentation()
slide_layout = prs.slide_layouts[1]  # Title and Content layout
slide = prs.slides.add_slide(slide_layout)

title = slide.shapes.title
title.text = "Ti√™u ƒë·ªÅ Slide"

content = slide.placeholders[1]
tf = content.text_frame
tf.text = "N·ªôi dung ch√≠nh"
p = tf.add_paragraph()
p.text = "‚Ä¢ ƒêi·ªÉm 1"
p.level = 1

prs.save('output.pptx')
\end{verbatim}

V·ªÅ h·ªó tr·ª£ Unicode, python-pptx x·ª≠ l√Ω t·ªët c√°c k√Ω t·ª± Unicode bao g·ªìm ti·∫øng Vi·ªát c√≥ d·∫•u, ƒë√°p ·ª©ng y√™u c·∫ßu NFR11 v·ªÅ h·ªó tr·ª£ ti·∫øng Vi·ªát ho√†n to√†n.

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá x·ª≠ l√Ω t√†i li·ªáu}

\subsection{V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt}

Theo y√™u c·∫ßu UC01.1, h·ªá th·ªëng c·∫ßn ƒë·ªçc v√† tr√≠ch xu·∫•t n·ªôi dung t·ª´ nhi·ªÅu ƒë·ªãnh d·∫°ng t√†i li·ªáu: PDF, DOCX, TXT, v√† MD. M·ªói ƒë·ªãnh d·∫°ng c√≥ c·∫•u tr√∫c v√† encoding kh√°c nhau, ƒë√≤i h·ªèi c√°c c√¥ng c·ª• x·ª≠ l√Ω chuy√™n bi·ªát.

\subsection{C√°c th∆∞ vi·ªán ƒë∆∞·ª£c s·ª≠ d·ª•ng}

	extbf{PyPDF} (pypdf) \cite{pypdf_docs} ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë·ªçc file PDF. ƒê√¢y l√† th∆∞ vi·ªán pure Python, kh√¥ng y√™u c·∫ßu dependencies b√™n ngo√†i, h·ªó tr·ª£ ƒë·ªçc text, metadata, v√† c√≥ th·ªÉ x·ª≠ l√Ω file PDF ƒë∆∞·ª£c encrypt.

	extbf{python-docx} \cite{python_docx_docs} ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë·ªçc file Microsoft Word (.docx). Th∆∞ vi·ªán n√†y parse file DOCX (th·ª±c ch·∫•t l√† file ZIP ch·ª©a XML) v√† extract n·ªôi dung text t·ª´ paragraphs, tables, v√† headers.

ƒê·ªëi v·ªõi file TXT v√† MD, h·ªá th·ªëng s·ª≠ d·ª•ng Python built-in file I/O v·ªõi encoding UTF-8 ƒë·ªÉ ƒë·∫£m b·∫£o h·ªó tr·ª£ ti·∫øng Vi·ªát.

\begin{verbatim}
# V√≠ d·ª• ƒë·ªçc c√°c ƒë·ªãnh d·∫°ng file
from pypdf import PdfReader
import docx

def extract_text(file_path: str, file_type: str) -> str:
    if file_type == "pdf":
        reader = PdfReader(file_path)
        return "\n".join(page.extract_text() for page in reader.pages)
    elif file_type == "docx":
        doc = docx.Document(file_path)
        return "\n".join(para.text for para in doc.paragraphs)
    else:  # txt, md
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
\end{verbatim}

\noindent\rule{\linewidth}{0.4pt}

\section{C√¥ng ngh·ªá tri·ªÉn khai v√† v·∫≠n h√†nh}

\subsection{Docker v√† Containerization}

	extbf{Docker} \cite{docker_docs} ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√≥ng g√≥i ·ª©ng d·ª•ng v√† dependencies v√†o container, ƒë√°p ·ª©ng y√™u c·∫ßu NFR21 v·ªÅ containerization. Dockerfile ƒë∆∞·ª£c thi·∫øt k·∫ø v·ªõi multi-stage build ƒë·ªÉ t·ªëi ∆∞u image size.

L·ª£i √≠ch c·ªßa vi·ªác s·ª≠ d·ª•ng Docker bao g·ªìm: (i) m√¥i tr∆∞·ªùng nh·∫•t qu√°n gi·ªØa development v√† production, (ii) d·ªÖ d√†ng scale v√† deploy, (iii) isolation gi·ªØa c√°c service, v√† (iv) version control cho infrastructure.

\begin{verbatim}
# Multi-stage Dockerfile
FROM python:3.11-slim as builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY . .
EXPOSE 8000 8501
CMD ["uvicorn", "backend.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
\end{verbatim}

\subsection{Nginx Reverse Proxy}

	extbf{Nginx} \cite{nginx_docs} ƒë∆∞·ª£c s·ª≠ d·ª•ng l√†m reverse proxy ph√≠a tr∆∞·ªõc FastAPI v√† Streamlit servers. Nginx ƒë·∫£m nhi·ªám: (i) load balancing n·∫øu c·∫ßn scale, (ii) SSL termination cho HTTPS, (iii) caching static files, v√† (iv) request routing d·ª±a tr√™n URL path.

\subsection{SQLite Database}

	extbf{SQLite} \cite{sqlite_docs} ƒë∆∞·ª£c ch·ªçn l√†m database ch√≠nh cho l∆∞u tr·ªØ metadata t√†i li·ªáu v√† l·ªãch s·ª≠ h·ªôi tho·∫°i. SQLite l√† embedded database, kh√¥ng c·∫ßn setup server ri√™ng, ph√π h·ª£p v·ªõi quy m√¥ tri·ªÉn khai single-server c·ªßa h·ªá th·ªëng.

\noindent\rule{\linewidth}{0.4pt}

\section{T·ªïng h·ª£p c√¥ng ngh·ªá v√† y√™u c·∫ßu}

B·∫£ng d∆∞·ªõi ƒë√¢y t·ªïng h·ª£p m·ªëi quan h·ªá gi·ªØa c√°c c√¥ng ngh·ªá ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† c√°c y√™u c·∫ßu ch·ª©c nƒÉng/phi ch·ª©c nƒÉng ƒë√£ x√°c ƒë·ªãnh t·∫°i Ch∆∞∆°ng 2:

\begin{table}[H]
\centering{}
    \begin{tabular}{|p{5.0cm}|p{10.0cm}|}
        \hline
        \textbf{Y√™u c·∫ßu} & \textbf{C√¥ng ngh·ªá gi·∫£i quy·∫øt} \\ \hline
        UC01: Ph√¢n t√≠ch t√†i li·ªáu & PyPDF, python-docx, LangChain \\ \hline
        UC01.3: RAG Q\&A & FAISS, HuggingFace Embeddings, LangChain \\ \hline
        UC02: T·∫°o slide & python-pptx, Ollama/LLM \\ \hline
        UC03: T·∫°o quiz & Ollama/LLM, LangChain \\ \hline
        UC04: Qu·∫£n l√Ω model & Ollama API \\ \hline
        NFR01-03: Hi·ªáu nƒÉng & FastAPI async, caching \\ \hline
        NFR10-12: Usability & Streamlit \\ \hline
        NFR14-17: B·∫£o m·∫≠t & Ollama (on-premise), FAISS (local) \\ \hline
        NFR18-21: B·∫£o tr√¨ & Docker, ki·∫øn tr√∫c ph√¢n l·ªõp \\ \hline
    \end{tabular}
    \caption{T·ªïng h·ª£p c√¥ng ngh·ªá v√† y√™u c·∫ßu}
    \label{tab:tech_requirement_mapping}
\end{table}

\noindent\rule{\linewidth}{0.4pt}

\section*{K·∫øt lu·∫≠n ch∆∞∆°ng}

Ch∆∞∆°ng 3 ƒë√£ tr√¨nh b√†y chi ti·∫øt c√°c c√¥ng ngh·ªá ƒë∆∞·ª£c s·ª≠ d·ª•ng trong h·ªá th·ªëng AI NVCB v√† l√Ω gi·∫£i s·ª± l·ª±a ch·ªçn c·ªßa t·ª´ng c√¥ng ngh·ªá. Ki·∫øn tr√∫c ph√¢n l·ªõp v·ªõi FastAPI backend, Streamlit frontend, v√† Ollama/LangChain cho AI processing t·∫°o n√™n m·ªôt h·ªá th·ªëng module h√≥a, d·ªÖ b·∫£o tr√¨ v√† m·ªü r·ªông.

ƒêi·ªÉm n·ªïi b·∫≠t c·ªßa stack c√¥ng ngh·ªá l√† kh·∫£ nƒÉng tri·ªÉn khai ho√†n to√†n on-premise v·ªõi Ollama v√† FAISS, ƒë·∫£m b·∫£o b·∫£o m·∫≠t d·ªØ li·ªáu ng∆∞·ªùi d√πng. Vi·ªác s·ª≠ d·ª•ng Python xuy√™n su·ªët t·ª´ frontend ƒë·∫øn backend v√† AI layer gi√∫p team development c√≥ th·ªÉ l√†m vi·ªác hi·ªáu qu·∫£ v·ªõi m·ªôt ng√¥n ng·ªØ duy nh·∫•t.

C√°c c√¥ng ngh·ªá n√†y s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng c·ª• th·ªÉ trong qu√° tr√¨nh thi·∫øt k·∫ø v√† tri·ªÉn khai h·ªá th·ªëng ·ªü Ch∆∞∆°ng 4.

\noindent\rule{\linewidth}{0.4pt}

\section*{T√†i li·ªáu tham kh·∫£o}

\bibliographystyle{plain}
\bibliography{docs/lib}

\end{document}
