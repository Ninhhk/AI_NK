# AI-NVCB Environment Variables
# Copy this file to .env and adjust values as needed

# Ollama Configuration
MODEL_NAME=gemma3:1b
OLLAMA_BASE_URL=http://localhost:11434

# Backend Server Configuration
# Uncomment to change from default values
# HOST=0.0.0.0
# PORT=8000
# LOG_LEVEL=debug

# Frontend Configuration
# Uncomment to change from default values
# STREAMLIT_SERVER_PORT=8501
# STREAMLIT_SERVER_HEADLESS=true

# Optional Features
# Uncomment to enable
# DEBUG_MODE=false
# ENABLE_TELEMETRY=false 