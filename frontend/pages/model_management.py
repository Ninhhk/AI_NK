import streamlit as st
import requests
import json
import time
import os
from io import BytesIO
import sys
from pathlib import Path

# Add the project root to the Python path
sys.path.append(str(Path(__file__).parent.parent.parent))
from frontend.components.system_prompt import system_prompt_ui

# Set page config for better appearance
st.set_page_config(
    page_title="AI Model Manager",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Load custom CSS
with open('frontend/style.css') as f:
    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)       

# Add custom styles for model management
st.markdown("""
    <style>
    .model-card {
        background-color: var(--card-background);
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        border: 1px solid rgba(255, 255, 255, 0.1);
        transition: all 0.3s ease;
    }
    .model-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(52, 152, 219, 0.2);
    }
    .model-progress {
        background-color: var(--primary-color-light);
        border-radius: 5px;
        height: 12px;
        margin-top: 0.5rem;
        overflow: hidden;
    }
    .model-progress-inner {
        background: linear-gradient(to right, var(--primary-color), var(--accent-color));
        height: 100%;
        transition: width 0.3s ease;
    }
    .model-actions {
        display: flex;
        gap: 0.5rem;
        margin-top: 1rem;
    }
    .model-icon {
        font-size: 2rem;
        margin-right: 1rem;
    }
    .model-header {
        display: flex;
        align-items: center;
    }
    </style>
""", unsafe_allow_html=True)

# API endpoints
OLLAMA_API_URL = "http://localhost:8000/api/ollama"
SLIDES_API_URL = "http://localhost:8000/api/slides"

def get_models():
    """Fetch all available models from API"""
    try:
        response = requests.get(f"{OLLAMA_API_URL}/models")
        response.raise_for_status()
        return response.json()["models"]
    except Exception as e:
        st.error(f"Error fetching models: {e}")
        return []

def get_current_model():
    """Get the currently active model for slide generation"""
    try:
        response = requests.get(f"{SLIDES_API_URL}/current-model")
        response.raise_for_status()
        return response.json()["model_name"]
    except Exception as e:
        st.error(f"Error fetching current model: {e}")
        return None

def set_model(model_name):
    """Set the model for slide generation"""
    try:
        response = requests.post(
            f"{SLIDES_API_URL}/set-model",
            data={"model_name": model_name}
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Error setting model: {e}")
        return None

def pull_model(model_name):
    """Start pulling a model from Ollama"""
    try:
        response = requests.post(
            f"{OLLAMA_API_URL}/models/pull",
            data={"model_name": model_name}
        )
        response.raise_for_status()
        return model_name  # Return the model name as the task ID
    except Exception as e:
        st.error(f"Error pulling model: {e}")
        return None

def get_download_progress(task_id):
    """Get download progress for a specific task"""
    try:
        # In the simplified version, we don't track progress
        # So we'll just return a dummy object
        return {"done": True, "pull_progress": 1000, "error": None}
    except Exception as e:
        return {"done": False, "pull_progress": 0, "error": str(e)}

def get_all_progress():
    """Get all download progress"""
    try:
        # In the simplified version, we don't track progress
        return {}
    except Exception as e:
        return {}

def cancel_model_pull(task_id):
    """Cancel model pull"""
    # In the simplified version, we don't support cancellation
    return True

def delete_model(model_name):
    """Delete a model"""
    try:
        response = requests.delete(f"{OLLAMA_API_URL}/models/{model_name}") 
        response.raise_for_status()
        return response.json()["success"]
    except Exception as e:
        st.error(f"Error deleting model: {e}")
        return False

def upload_model(file, model_name=None):
    """Upload a model file"""
    # In our simplified version, we don't support file uploads
    st.warning("Model file uploads are not supported in this version")      
    return False

def get_system_prompt():
    """Get the current system prompt."""
    try:
        response = requests.get(f"{OLLAMA_API_URL}/system-prompt")
        response.raise_for_status()
        return response.json()["system_prompt"]
    except Exception as e:
        st.error(f"Error fetching system prompt: {e}")
        return ""

def set_system_prompt(prompt):
    """Set the system prompt."""
    try:
        response = requests.post(
            f"{OLLAMA_API_URL}/system-prompt",
            data={"system_prompt": prompt}
        )
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"Error setting system prompt: {e}")
        return None

# Header section with animated logo and title
col1, col2, col3 = st.columns([1,2,1])
with col2:
    st.markdown("""
        <div class="fade-in">
            <h1 style='text-align: center; color: var(--primary-color); font-size: 2.5em; margin-bottom: 0.5em;'>
                ü§ñ Model Management
            </h1>
            <h3 style='text-align: center; color: var(--text-secondary); font-size: 1.2em;'>
                Manage Your AI Models for All Application Features
            </h3>
        </div>
    """, unsafe_allow_html=True)

# Main content area with animated separator
st.markdown("""
    <div style='height: 2px; background: linear-gradient(90deg, transparent, var(--primary-color), transparent);'></div>
""", unsafe_allow_html=True)

# Tabs for different sections
tab1, tab2, tab3, tab4 = st.tabs(["Available Models", "Add New Model", "System Prompt", "Active Downloads"])

with tab1:
    # Fetch current model
    current_model = get_current_model()
    
    # Refresh button
    if st.button("üîÑ Refresh Models", type="primary"):
        st.experimental_rerun()
    
    # Get models
    models = get_models()
    
    if not models:
        st.info("No models available. Add models in the 'Add New Model' tab.")
    else:
        st.markdown(f"### Available Models ({len(models)})")
        st.markdown("Select a model to use for all features (slide generation, document analysis, and quiz generation)")
        
        # Display global notification about the current model
        if current_model:
            st.info(f"üîÑ **Current Active Model: {current_model}** - This model is currently used across all application features.", icon="‚ÑπÔ∏è")
        
        for model in models:
            with st.container():
                st.markdown(f"""
                <div class="model-card">
                    <div class="model-header">
                        <div class="model-icon">üß†</div>
                        <div>
                            <h3 style="margin: 0;">{model['name']}</h3>     
                            <p style="margin: 0; color: var(--text-secondary);">
                                Size: {model['size'] / (1024*1024):.1f} MB | Modified: {model['modified_at']}
                            </p>
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # Action buttons in columns
                col1, col2, col3, col4 = st.columns([1, 1, 1, 3])
                
                with col1:
                    if st.button(f"Select", key=f"select_{model['name']}"):
                        result = set_model(model['name'])
                        if result:
                            st.success(f"Model changed to {model['name']} and will be used across all features")
                            time.sleep(1)
                            st.experimental_rerun()
                
                with col2:
                    if st.button(f"Info", key=f"info_{model['name']}"):
                        st.json(model['details'] if 'details' in model else model)
                
                with col3:
                    if st.button(f"Delete", key=f"delete_{model['name']}"):
                        if model['name'] == current_model:
                            st.error("Cannot delete the currently active model")
                        else:
                            if delete_model(model['name']):
                                st.success(f"Model {model['name']} deleted")
                                time.sleep(1)
                                st.experimental_rerun()
                
                with col4:
                    if model['name'] == current_model:
                        st.success("‚úÖ Current global model")

with tab2:
    st.markdown("### Add a New Model")
    
    # Model pull section
    with st.expander("Pull Model from Ollama", expanded=True):
        st.markdown("""
        Enter the name of an Ollama model to download. Examples:
        - `llama3:8b`
        - `gemma3:1b`
        - `mistral:latest`
        """)
        
        with st.form("pull_model_form"):
            model_name = st.text_input("Model Name", placeholder="e.g., llama3:8b")
            submitted = st.form_submit_button("Start Download")
            
            if submitted and model_name:
                task_id = pull_model(model_name)
                if task_id:
                    st.success(f"Started downloading {model_name}")
                    time.sleep(1)
                    st.experimental_rerun()
    
    # Model upload section
    with st.expander("Upload GGUF Model File", expanded=False):
        st.markdown("""
        Upload a GGUF model file directly. This will be added to Ollama.
        """)
        
        with st.form("upload_model_form"):
            uploaded_file = st.file_uploader("Select GGUF file", type=["gguf"])
            custom_name = st.text_input("Custom Model Name (optional)")
            upload_submitted = st.form_submit_button("Upload Model")
            
            if upload_submitted and uploaded_file:
                success = upload_model(uploaded_file, custom_name if custom_name else None)
                if success:
                    st.success(f"Model uploaded successfully")
                    time.sleep(1)
                    st.experimental_rerun()

with tab3:
    st.markdown("### Global System Prompt")
    st.markdown("""
    <div class="card fade-in">
        <p>
            The system prompt is used across all features of the application to control how the AI responds. 
            This is a global setting that affects slide generation, document analysis, and all other AI interactions.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # First get the current system prompt from the API
    current_system_prompt = ""
    try:
        current_system_prompt = get_system_prompt()
    except:
        # If API is not available, use an empty default prompt
        pass
        
    # Show the system prompt UI component
    system_prompt = system_prompt_ui(default_prompt=current_system_prompt, key_prefix="model_management")
    
    # Add a button to save the system prompt globally
    col1, col2 = st.columns([1, 3])
    with col1:
        if st.button("üíæ Save System Prompt Globally", type="primary"):
            result = set_system_prompt(system_prompt)
            if result:
                st.success("‚úÖ System prompt saved globally and will be used across all features")
            else:
                st.error("‚ùå Failed to save system prompt")
    
    with col2:
        st.warning("This will update the system prompt for **all features** of the application.")
    
    # Add a button to run the set_system_prompt.py script
    st.markdown("---")
    st.markdown("### Reset to Vietnamese Prompt")
    
    if st.button("üîÑ Reset to Vietnamese Prompt"):
        try:
            vietnamese_prompt = "\\no_think must answer in vietnamese, ph·∫£i tr·∫£ l·ªùi b·∫±ng ti·∫øng vi·ªát"
            result = set_system_prompt(vietnamese_prompt)
            if result:
                st.success("‚úÖ System prompt reset to Vietnamese response requirement")
                time.sleep(1)
                st.experimental_rerun()
            else:
                st.error("‚ùå Failed to reset system prompt")
        except Exception as e:
            st.error(f"Error resetting system prompt: {e}")

with tab4:
    st.markdown("### Active Downloads")
    
    # Auto-refresh for download progress
    auto_refresh = st.checkbox("Auto-refresh (every 2 seconds)", value=True)
    
    # Get all download progress
    download_progress = get_all_progress()
    
    if not download_progress:
        st.info("No active downloads. Start a download in the 'Add New Model' tab.")
    else:
        for model_name, progress in download_progress.items():
            with st.container():
                # Calculate percentage for display
                percentage = progress.get("pull_progress", 0) / 10 if progress.get("pull_progress") is not None else 0
                
                st.markdown(f"""
                <div class="model-card">
                    <h3>{model_name}</h3>
                    <p>Status: {"Completed" if progress.get("done", False) else "Downloading..."}</p>
                    <div class="model-progress">
                        <div class="model-progress-inner" style="width: {percentage}%;"></div>
                    </div>
                    <p>{percentage:.1f}% complete</p>
                </div>
                """, unsafe_allow_html=True)
                
                # Cancel button
                if not progress.get("done", False):
                    if st.button(f"Cancel", key=f"cancel_{model_name}"):
                        if cancel_model_pull(model_name):
                            st.success(f"Cancelled download of {model_name}")
                            time.sleep(1)
                            st.experimental_rerun()
    
    # Auto-refresh logic
    if auto_refresh and download_progress:
        time.sleep(2)
        st.experimental_rerun()

# Footer with gradient separator
st.markdown("""
    <div style='height: 2px; background: linear-gradient(90deg, transparent, var(--primary-color), transparent);'></div>
    <div class="footer fade-in">
        <p style='margin: 0.5em 0;'>Powered by Ollama | Made with ‚ù§Ô∏è</p>
    </div>
""", unsafe_allow_html=True)
