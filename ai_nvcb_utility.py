#!/usr/bin/env python3
"""
AI NVCB Utility Script

This script combines environment setup and model cleanup functionality.
Choose what you want to do from the interactive menu.
"""

import os
import sys
import shutil
import json
import subprocess
import argparse
from pathlib import Path
from typing import List, Dict, Any


class AINCVBUtility:
    """Combined utility for AI NVCB environment and model management."""
    
    def __init__(self):
        self.script_dir = Path(__file__).parent
        self.env_example_path = self.script_dir / ".env.example"
        self.env_path = self.script_dir / ".env"
    
    def show_banner(self):
        """Show application banner."""
        print("üõ†Ô∏è  AI NVCB Utility Tool")
        print("=" * 50)
        print("C√¥ng c·ª• ti·ªán √≠ch cho thi·∫øt l·∫≠p v√† b·∫£o tr√¨ h·ªá th·ªëng")
        print()
    
    def show_menu(self):
        """Show interactive menu."""
        print("üìã Ch·ªçn ch·ª©c nƒÉng:")
        print("1. üîß Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng (.env.example ‚Üí .env)")
        print("2. üßπ D·ªçn d·∫πp AI models kh√¥ng s·ª≠ d·ª•ng")
        print("3. üöÄ Th·ª±c hi·ªán c·∫£ hai (thi·∫øt l·∫≠p + d·ªçn d·∫πp)")
        print("4. ‚ùå Tho√°t")
        print()
        
        while True:
            try:
                choice = input("Nh·∫≠p l·ª±a ch·ªçn (1-4): ").strip()
                if choice in ['1', '2', '3', '4']:
                    return int(choice)
                else:
                    print("‚ö†Ô∏è Vui l√≤ng nh·∫≠p s·ªë t·ª´ 1-4")
            except KeyboardInterrupt:
                print("\nüëã T·∫°m bi·ªát!")
                sys.exit(0)
    
    # ==================== ENVIRONMENT SETUP ====================
    
    def copy_env_example(self) -> bool:
        """Copy .env.example to .env file."""
        print("\nüîß THI·∫æT L·∫¨P M√îI TR∆Ø·ªúNG")
        print("-" * 30)
        
        try:
            # Check if .env.example exists
            if not self.env_example_path.exists():
                print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file .env.example!")
                print(f"   V·ªã tr√≠ mong ƒë·ª£i: {self.env_example_path}")
                return False
            
            # Check if .env already exists
            if self.env_path.exists():
                print("‚ö†Ô∏è  C·∫£nh b√°o: File .env ƒë√£ t·ªìn t·∫°i!")
                response = input("   B·∫°n c√≥ mu·ªën ghi ƒë√® kh√¥ng? (y/N): ").strip().lower()
                if response not in ('y', 'yes'):
                    print("   H·ªßy b·ªè thao t√°c.")
                    return False
            
            # Copy the file
            shutil.copy2(self.env_example_path, self.env_path)
            
            # Verify the copy
            if self.env_path.exists():
                print("‚úÖ Sao ch√©p th√†nh c√¥ng .env.example ‚Üí .env")
                
                # Show the content
                print("\nüìÑ N·ªôi dung file .env:")
                print("-" * 40)
                with open(self.env_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    print(content)
                print("-" * 40)
                
                return True
            else:
                print("‚ùå L·ªói: Kh√¥ng th·ªÉ t·∫°o file .env")
                return False
                
        except PermissionError:
            print("‚ùå L·ªói: Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p!")
            print("   Th·ª≠ ch·∫°y v·ªõi quy·ªÅn Administrator.")
            return False
        except Exception as e:
            print(f"‚ùå L·ªói: {str(e)}")
            return False
    
    # ==================== MODEL CLEANUP ====================
    
    def get_current_model(self) -> str:
        """Get the current model from .env file."""
        try:
            if self.env_path.exists():
                with open(self.env_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.startswith('MODEL_NAME='):
                            return line.split('=', 1)[1].strip()
            return "qwen3:8b"  # Default fallback
        except Exception:
            return "qwen3:8b"
    
    def get_ollama_models(self) -> List[Dict[str, Any]]:
        """Get list of Ollama models."""
        try:
            result = subprocess.run(
                ['ollama', 'list'],
                capture_output=True,
                text=True,
                check=True
            )
            
            models = []
            lines = result.stdout.strip().split('\n')[1:]  # Skip header
            
            for line in lines:
                if line.strip():
                    parts = line.split()
                    if len(parts) >= 3:
                        name = parts[0]
                        size = parts[2] if len(parts) > 2 else "Unknown"
                        models.append({
                            'name': name,
                            'size': size,
                            'raw_line': line
                        })
            
            return models
        except subprocess.CalledProcessError:
            print("‚ùå L·ªói: Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi Ollama")
            print("   ƒê·∫£m b·∫£o Ollama ƒëang ch·∫°y: ollama serve")
            return []
        except FileNotFoundError:
            print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y Ollama")
            print("   C√†i ƒë·∫∑t Ollama t·ª´: https://ollama.ai")
            return []
    
    def pull_model(self, model_name: str) -> bool:
        """Download/pull a model using Ollama."""
        try:
            print(f"üì• ƒêang t·∫£i model: {model_name}...")
            print("   (Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t t√πy thu·ªôc v√†o k√≠ch th∆∞·ªõc model)")
            
            result = subprocess.run(
                ['ollama', 'pull', model_name],
                check=True,
                text=True
            )
            
            print(f"‚úÖ T·∫£i th√†nh c√¥ng model: {model_name}")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå L·ªói khi t·∫£i model {model_name}: {e}")
            return False
        except FileNotFoundError:
            print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y Ollama")
            print("   C√†i ƒë·∫∑t Ollama t·ª´: https://ollama.ai")
            return False
    
    def cleanup_models(self, dry_run: bool = False, force: bool = False, keep_models: List[str] = None) -> bool:
        """Clean up unused Ollama models."""
        print("\nüßπ D·ªåN D·∫∏P AI MODELS")
        print("-" * 30)
        
        if keep_models is None:
            keep_models = []
        
        # Get current model from .env
        current_model = self.get_current_model()
        print(f"üìå Model ƒëang s·ª≠ d·ª•ng: {current_model}")
          # Get all models
        models = self.get_ollama_models()
        if models is None:  # Error occurred
            return False
        
        # Check if target model exists
        current_model_exists = any(model['name'] == current_model for model in models)
        
        if not current_model_exists:
            print(f"\n‚ö†Ô∏è  Model c·∫ßn thi·∫øt kh√¥ng t·ªìn t·∫°i: {current_model}")
            if dry_run:
                print("üîç Ch·∫ø ƒë·ªô xem tr∆∞·ªõc - s·∫Ω t·∫£i model n√†y")
            else:
                if not force:
                    response = input(f"B·∫°n c√≥ mu·ªën t·∫£i model {current_model} kh√¥ng? (Y/n): ").strip().lower()
                    if response in ('n', 'no'):
                        print("‚ùå H·ªßy b·ªè thao t√°c.")
                        return False
                
                # Download the target model
                if not self.pull_model(current_model):
                    print(f"‚ùå Kh√¥ng th·ªÉ t·∫£i model {current_model}")
                    return False
                  # Refresh the model list after download
                models = self.get_ollama_models()
                if not models:
                    return False
        
        if not models:
            print("\nüì≠ Kh√¥ng c√≥ model n√†o ƒë∆∞·ª£c c√†i ƒë·∫∑t!")
            if dry_run:
                print(f"üîç Ch·∫ø ƒë·ªô xem tr∆∞·ªõc - s·∫Ω t·∫£i model {current_model}")
                return True
            else:
                if not force:
                    response = input(f"B·∫°n c√≥ mu·ªën t·∫£i model {current_model} kh√¥ng? (Y/n): ").strip().lower()
                    if response in ('n', 'no'):
                        print("‚ùå H·ªßy b·ªè thao t√°c.")
                        return False
                
                # Download the target model
                return self.pull_model(current_model)
        
        # Determine which models to keep
        models_to_keep = {current_model} | set(keep_models)
        models_to_delete = []
        
        print(f"\nüìã T√¨m th·∫•y {len(models)} model(s):")
        for model in models:
            name = model['name']
            size = model['size']
            
            if name in models_to_keep:
                status = "‚úÖ (gi·ªØ l·∫°i)"
            else:
                status = "‚ùå (s·∫Ω x√≥a)"
                models_to_delete.append(model)
            
            print(f"   {name} ({size}) {status}")
        
        if not models_to_delete:
            print("\nüéâ Kh√¥ng c√≥ model n√†o c·∫ßn x√≥a!")
            return True
        
        # Show models to be deleted
        print(f"\nüóëÔ∏è  C√°c model s·∫Ω b·ªã x√≥a ({len(models_to_delete)}):")
        total_space_estimate = 0
        for model in models_to_delete:
            print(f"   - {model['name']} ({model['size']})")
            # Rough estimate of space (very approximate)
            size_str = model['size'].lower()
            if 'gb' in size_str:
                try:
                    gb_val = float(size_str.replace('gb', '').strip())
                    total_space_estimate += gb_val
                except:
                    pass
        
        if total_space_estimate > 0:
            print(f"\nüíæ ∆Ø·ªõc t√≠nh ti·∫øt ki·ªám: ~{total_space_estimate:.1f} GB")
        
        if dry_run:
            print("\nüîç Ch·∫ø ƒë·ªô xem tr∆∞·ªõc - kh√¥ng x√≥a th·ª±c t·∫ø")
            return True
        
        # Confirm deletion
        if not force:
            print(f"\n‚ö†Ô∏è  C·∫¢NH B√ÅO: Thao t√°c n√†y s·∫Ω X√ìA Vƒ®NH VI·ªÑN {len(models_to_delete)} model(s)!")
            response = input("B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën ti·∫øp t·ª•c? (y/N): ").strip().lower()
            if response not in ('y', 'yes'):
                print("H·ªßy b·ªè thao t√°c.")
                return False
        
        # Delete models
        success_count = 0
        for model in models_to_delete:
            name = model['name']
            try:
                result = subprocess.run(
                    ['ollama', 'rm', name],
                    capture_output=True,
                    text=True,
                    check=True
                )
                print(f"‚úÖ ƒê√£ x√≥a: {name}")
                success_count += 1
            except subprocess.CalledProcessError as e:
                print(f"‚ùå L·ªói khi x√≥a {name}: {e}")
        
        if success_count > 0:
            print(f"\nüéâ D·ªçn d·∫πp ho√†n t·∫•t! ƒê√£ x√≥a {success_count}/{len(models_to_delete)} model(s)")
            if total_space_estimate > 0:
                proportion = success_count / len(models_to_delete)
                estimated_saved = total_space_estimate * proportion
                print(f"üíæ ∆Ø·ªõc t√≠nh ti·∫øt ki·ªám: ~{estimated_saved:.1f} GB")
            return True
        else:
            print("‚ùå Kh√¥ng th·ªÉ x√≥a model n√†o")
            return False
    
    # ==================== COMBINED OPERATIONS ====================
    
    def run_both(self) -> bool:
        """Run both environment setup and model cleanup."""
        print("\nüöÄ TH·ª∞C HI·ªÜN C·∫¢ HAI CH·ª®C NƒÇNG")
        print("=" * 40)
        
        # Step 1: Environment setup
        env_success = self.copy_env_example()
        
        if env_success:
            print("\n‚è±Ô∏è  Ch·ªù 2 gi√¢y tr∆∞·ªõc khi d·ªçn d·∫πp models...")
            import time
            time.sleep(2)
            
            # Step 2: Model cleanup
            cleanup_success = self.cleanup_models()
            
            if cleanup_success:
                print("\nüéâ Ho√†n th√†nh t·∫•t c·∫£ c√°c thao t√°c!")
                return True
            else:
                print("\n‚ö†Ô∏è  Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng th√†nh c√¥ng, nh∆∞ng d·ªçn d·∫πp models th·∫•t b·∫°i")
                return False
        else:
            print("\n‚ùå Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng th·∫•t b·∫°i, b·ªè qua d·ªçn d·∫πp models")
            return False
    
    # ==================== MAIN INTERFACE ====================
    
    def run_interactive(self):
        """Run interactive mode."""
        self.show_banner()
        
        while True:
            choice = self.show_menu()
            
            if choice == 1:
                success = self.copy_env_example()
                if success:
                    print("\nüí° B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y ·ª©ng d·ª•ng:")
                    print("   python run_backend.py")
                    print("   python run_frontend.py")
            
            elif choice == 2:
                self.cleanup_models()
            
            elif choice == 3:
                success = self.run_both()
                if success:
                    print("\nüí° B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y ·ª©ng d·ª•ng:")
                    print("   python run_backend.py")
                    print("   python run_frontend.py")
            
            elif choice == 4:
                print("üëã T·∫°m bi·ªát!")
                break
            
            # Ask if user wants to continue
            print("\n" + "‚îÄ" * 50)
            continue_choice = input("B·∫°n c√≥ mu·ªën th·ª±c hi·ªán thao t√°c kh√°c? (Y/n): ").strip().lower()
            if continue_choice in ('n', 'no'):
                print("üëã T·∫°m bi·ªát!")
                break
            print()
    
    def run_command_line(self, args):
        """Run command line mode."""
        self.show_banner()
        
        if args.env_only:
            success = self.copy_env_example()
            if success:
                print("\nüí° B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y ·ª©ng d·ª•ng:")
                print("   python run_backend.py")
                print("   python run_frontend.py")
        
        elif args.cleanup_only:
            self.cleanup_models(
                dry_run=args.dry_run,
                force=args.force,
                keep_models=args.keep or []
            )
        
        elif args.both:
            success = self.run_both()
            if success:
                print("\nüí° B√¢y gi·ªù b·∫°n c√≥ th·ªÉ ch·∫°y ·ª©ng d·ª•ng:")
                print("   python run_backend.py")
                print("   python run_frontend.py")
        
        else:
            # No specific command, run interactive
            self.run_interactive()


def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="AI NVCB Utility - Environment setup and model cleanup tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  python ai_nvcb_utility.py                    # Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c
  python ai_nvcb_utility.py --env-only         # Ch·ªâ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng
  python ai_nvcb_utility.py --cleanup-only     # Ch·ªâ d·ªçn d·∫πp models
  python ai_nvcb_utility.py --both             # C·∫£ hai ch·ª©c nƒÉng
  python ai_nvcb_utility.py --cleanup-only --dry-run    # Xem tr∆∞·ªõc kh√¥ng x√≥a
  python ai_nvcb_utility.py --cleanup-only --keep mistral:7b  # Gi·ªØ l·∫°i model c·ª• th·ªÉ
        """
    )
    
    # Main actions
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        '--env-only',
        action='store_true',
        help='Ch·ªâ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng (.env.example ‚Üí .env)'
    )
    group.add_argument(
        '--cleanup-only',
        action='store_true',
        help='Ch·ªâ d·ªçn d·∫πp AI models kh√¥ng s·ª≠ d·ª•ng'
    )
    group.add_argument(
        '--both',
        action='store_true',
        help='Th·ª±c hi·ªán c·∫£ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng v√† d·ªçn d·∫πp models'
    )
    
    # Cleanup options
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Xem tr∆∞·ªõc models s·∫Ω b·ªã x√≥a (kh√¥ng x√≥a th·ª±c t·∫ø)'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='B·ªè qua x√°c nh·∫≠n (c·∫©n th·∫≠n!)'
    )
    parser.add_argument(
        '--keep',
        action='append',
        help='Gi·ªØ l·∫°i model c·ª• th·ªÉ (c√≥ th·ªÉ d√πng nhi·ªÅu l·∫ßn)'
    )
    
    return parser.parse_args()


def main():
    """Main function."""
    args = parse_args()
    utility = AINCVBUtility()
    
    try:
        utility.run_command_line(args)
    except KeyboardInterrupt:
        print("\nüëã T·∫°m bi·ªát!")
        sys.exit(0)
    except Exception as e:
        print(f"\n‚ùå L·ªói kh√¥ng mong ƒë·ª£i: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
